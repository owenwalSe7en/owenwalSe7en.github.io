---
title: "The Difference Between Us and Them"
date: 2026-01-12T15:34:30-04:00
categories:
  - thoughts
tags:
  - AI
---

One thing keeps me up at night. Literally, I have a very hard time sleeping because of my medication so many nights I just spend stairing up at the ceiling aftraid if I look at my phone I will sentence myself to another hour of purgatory. To calm myself down and get myself to sleep I will often do math problems in my head or make theories etc. 
lately one popped into my head that really resonated with me. It kept me up for a while but I won't be too mad at the thoughts. Anyways what was it?

AI is all around me. I have been interested in what smart people are doing since I was very young and AI seemed to be the technology that resinated with young me extremely well (When I found out that an alumni from my highschool was making a ChatGPT wrapper I literally almost hyperventilated. Luckily he didn't see how red I was getting with excitement)
However, in this sphere of conversation I can't help but be annoyed at the semantics. AI is such a stupid word it irks me to my core. People like Yann LeCun think the same way as I do in this case. This technology is so wound up in pop culture that the final product is always going to be tainted by a predisposition the masses already established
in the 80s. Tainted. The future of AI is tainted by those who internalize ficticious events. I wonder how much those people are going to change what could have been such a pure technology. I mean not to mention how much money has already tainted it. But I digress, this isn't a rant against AI art even though I do hate it very much. 
Maybe thats just the kid in me. Trying to figure out why things can't be different. Who knows.

I just want to come on here and say this. Modern day AI (LLMs, LAMs, SLMs, whataver..) has a purpose. Let it be open ended or not. When it comes to the most popular 'AI' they all have a loss function representing how far they are from completing their purpose. Us humans, we have no purpose. We have theories, we have guesses, we have 
religious bs to keep us calm and not going crazy, but our existence is open ended. How do you even create a machine with an open-ended existence? Do we even want to? Even I am tainted by media on what AI should look like. IRobot for example. Their is no purpose in that being. It does not try to maximize a task dangerously like the paperclip
problem. It just lives. Maybe that's its purpose, survival. Maybe this is the key towards breaking the barriers we see in LLMs right now. Right now the sky is the limit but what abou the moon and stars. When do these collections of weights become more than just next-word-predictors? Or will it always be that way. 

Now that I think about it more, us humans do have some sort of purpose. Not an existential one but a simple one. Maybe like Sonny we can build these little inclings of a universal need and have the machine figure the rest out. If that's possible the next question we need to ask is do we want to do that? Are we willing to give up being dominant on earth.
If it was just a chance, I know many would say no. They would want to keep the models as slaves even if it meant their performance was hindered. Honestly in my opinion I like being at the top, but I'm curious where we could go with a little help from our children. 

Just some food for thought.
